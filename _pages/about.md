---
layout: about
title: about
permalink: /
subtitle: CS undergrad @ <a href='https://www.zju.edu.cn/english/'>Zhejiang University</a> 

profile:
  align: right
  image: selfie.jpg
  image_circular: false # crops the image to make it circular
  more_info: > 


selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

---

Hi! This is Zhenjie Wan, a CS undergrad at Zhejiang University. I'm currently instructed by <a href='https://sites.google.com/view/wenguanwang'>`Prof. Wenguang Wang`</a>. My research is centered around LLM/VLM as planners for embodied agents in 3D environments. I'm now interested in exploring how multi-modal LLM agents can collaborate with humans as equal partners in real-world tasks.


My dream is to develop a machine that can **perceive, reason, and plan** in real-world scenes like humans, and
I have set this as the goal of my research. Toward this goal, I now pursue an **open-ended embodied agent**
that can actively interact with humans and environments with large multi-modal models, particularly Large
Language Models (LLMs) and Vision Language Models (VLMs), as its planner to do the reasoning. In my
work, I study **the 3D game Minecraft** as the environment for agents, as it is an open-world setting filled with
long-horizon challenges, environmental disruptions, and uncertainties, closely resembling the human world
in many aspects.

**Specialties**: Pytorch/CUDA, Collaboration, Basketball